{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1HJGMDnBhDYBODRuuDiLFulqB43WXxLt-","timestamp":1698017086459}],"machine_shape":"hm","mount_file_id":"19a7ZZyizocSfqruuCkR1ZAX8s8jGDvVo","authorship_tag":"ABX9TyOoxBb6Ej+Rxu5zes+qXEBB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Setup"],"metadata":{"id":"LI0qFEhwxhvs"}},{"cell_type":"code","source":["!pip install sentence_transformers"],"metadata":{"id":"afQ2yESlD8i7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import operator\n","import numpy as np\n","import pandas as pd\n","\n","import re\n","import string\n","import spacy\n","import gensim\n","import nltk\n","from gensim import corpora, models, matutils\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer\n","from nltk.tokenize import RegexpTokenizer\n","import spacy.lang.en\n","from scipy import spatial\n","from scipy.spatial.distance import cosine\n","\n","spacy_nlp = spacy.load('en_core_web_sm')\n","\n","nltk.download('stopwords')\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity"],"metadata":{"id":"4_s_Z1VK7Zmo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import BertModel, BertTokenizer\n","from sentence_transformers import SentenceTransformer\n","import torch"],"metadata":{"id":"3kvy3fOwIbdX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Preparing the Document Collection and User Query"],"metadata":{"id":"DbHBmCv7xo75"}},{"cell_type":"code","source":["# Set the directory where your documents are stored\n","document_dir = '/content/drive/MyDrive/file path'"],"metadata":{"id":"KHacyB637nPb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["For keyword-based searches, the process will include tokenization, the elimination of stopwords, and the option of either lemmatization or stemming to refine the words further.\n","\n","In contrast, for semantic search queries that leverage embeddings or neural models capable of grasping broader contexts, preprocessing will be more subdued. The primary focus here will be on tidying up the text to retain its original meaning as much as possible. Given that semantic search aims to grasp the query's context and underlying intent, the approach to preprocessing shifts away from significant word modifications towards cleaning the text to ensure it's in a suitable format for semantic models."],"metadata":{"id":"jLnmdxYd-NFX"}},{"cell_type":"code","source":["def lemmatize_and_stem(text, use_stemming=True):\n","    \"\"\"\n","    Function to lemmatize and optionally stem words in the text.\n","\n","    :param text: The input text as a string.\n","    :param use_stemming: Boolean indicating whether to use stemming.\n","    :return: Processed text tokens as a list.\n","    \"\"\"\n","    # Initialize Spacy tokenizer and NLTK stemmer\n","    stemmer = PorterStemmer()\n","\n","    # Lemmatization\n","    doc = spacy_nlp(text)\n","    tokens = [token.lemma_.lower().strip() for token in doc if token.lemma_ != \"-PRON-\"]\n","\n","    # Optional stemming\n","    if use_stemming:\n","        tokens = [stemmer.stem(token) for token in tokens]\n","\n","    return tokens"],"metadata":{"id":"JIDQD69w-0u5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess(text, use_for='search_type'):\n","    \"\"\"\n","    Function to preprocess text for either keyword-based or semantic search models.\n","\n","    :param text: The input text as a string.\n","    :param use_for: Specify 'keyword' for keyword-based model preprocessing, 'semantic' for semantic-based model.\n","    :return: Preprocessed text as a list of tokens.\n","    \"\"\"\n","    # Common preprocessing\n","    text = re.sub('\\'', '', text)  # remove distracting single quotes\n","    text = re.sub('\\w*\\d\\w*', '', text)  # remove digits and words containing digits\n","    text = re.sub(' +', ' ', text)  # replace extra spaces with single space\n","    text = re.sub(r'[^\\w\\s]', ' ', text)  # remove punctuations\n","    text = re.sub(r'\\n', ' ', text)  # remove non-breaking new line characters\n","\n","    if use_for == 'keyword':\n","        # Keyword-based model specific preprocessing\n","        tokenizer = RegexpTokenizer(r'\\w+')\n","        stop_words = set(stopwords.words('english'))\n","        tokens = tokenizer.tokenize(text.lower())\n","        tokens = [word for word in tokens if word not in stop_words and len(word) > 2]\n","        tokens = lemmatize_and_stem(text, use_stemming=False)\n","        tokens = [word for word in tokens if len(word) > 2]\n","        return tokens\n","    elif use_for == 'semantic':\n","        return text.strip()"],"metadata":{"id":"whQWi6UX-8jk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["For keyword search"],"metadata":{"id":"hIvTYyfj_KzW"}},{"cell_type":"code","source":["# Load and preprocess documents\n","texts = []\n","document_filenames = []\n","\n","for filename in os.listdir(document_dir):\n","    if filename.endswith(\".txt\"):\n","        filepath = os.path.join(document_dir, filename)\n","        with open(filepath, 'r', encoding='utf-8') as file:\n","            text = file.read()\n","            processed_text = preprocess(text, use_for='keyword')\n","            texts.append(processed_text)\n","            document_filenames.append(filename)"],"metadata":{"id":"BCXbY8L-7Yaq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a dictionary and corpus for retrieval\n","dictionary = corpora.Dictionary(texts)\n","corpus = [dictionary.doc2bow(text) for text in texts]"],"metadata":{"id":"pO6O-O-68HX0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#print top 50 items from the dictionary with their unique token-id\n","dict_tokens = [[[dictionary[key], dictionary.token2id[dictionary[key]]] for key, value in dictionary.items() if key <= 50]]\n","print (dict_tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b-OzwLhoG0IT","executionInfo":{"status":"ok","timestamp":1710513834345,"user_tz":420,"elapsed":4,"user":{"displayName":"Shawon Sarkar","userId":"05628563176525096143"}},"outputId":"19138015-dc23-4392-f670-eeb9928af4cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[['aberrant', 0], ['able', 1], ['abstract', 2], ['accurate', 3], ['across', 4], ['addition', 5], ['aim', 6], ['algorithm', 7], ['allele', 8], ['allelic', 9], ['allelotype', 10], ['allow', 11], ['almost', 12], ['also', 13], ['alteration', 14], ['amplification', 15], ['amplified', 16], ['amplify', 17], ['analysis', 18], ['analyze', 19], ['and', 20], ['apparent', 21], ['apply', 22], ['approach', 23], ['array', 24], ['arrive', 25], ['ascn', 26], ['available', 27], ['base', 28], ['because', 29], ['believe', 30], ['between', 31], ['both', 32], ['but', 33], ['can', 34], ['cancer', 35], ['candidate', 36], ['category', 37], ['cause', 38], ['cell', 39], ['central', 40], ['chromatid', 41], ['chromosomal', 42], ['chromosome', 43], ['citation', 44], ['classification', 45], ['classify', 46], ['collection', 47], ['combine', 48], ['complicate', 49], ['conceivably', 50]]]\n"]}]},{"cell_type":"code","source":["word_frequencies = [[(dictionary[id], frequency) for id, frequency in line] for line in corpus[0:3]]\n","print(word_frequencies)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K6GgDwkpBmJE","executionInfo":{"status":"ok","timestamp":1710513837523,"user_tz":420,"elapsed":484,"user":{"displayName":"Shawon Sarkar","userId":"05628563176525096143"}},"outputId":"08c9750a-2200-4ba1-82ad-cce95b1116e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[('aberrant', 1), ('able', 4), ('abstract', 1), ('accurate', 1), ('across', 4), ('addition', 1), ('aim', 1), ('algorithm', 2), ('allele', 8), ('allelic', 1), ('allelotype', 2), ('allow', 1), ('almost', 1), ('also', 4), ('alteration', 5), ('amplification', 14), ('amplified', 1), ('amplify', 5), ('analysis', 1), ('analyze', 2), ('and', 13), ('apparent', 1), ('apply', 2), ('approach', 2), ('array', 5), ('arrive', 1), ('ascn', 1), ('available', 1), ('base', 2), ('because', 3), ('believe', 2), ('between', 1), ('both', 2), ('but', 1), ('can', 1), ('cancer', 6), ('candidate', 1), ('category', 1), ('cause', 2), ('cell', 3), ('central', 1), ('chromatid', 1), ('chromosomal', 2), ('chromosome', 5), ('citation', 14), ('classification', 1), ('classify', 1), ('collection', 1), ('combine', 1), ('complicate', 1), ('conceivably', 1), ('conclude', 1), ('confirm', 1), ('constant', 1), ('contain', 3), ('contribution', 1), ('copy', 15), ('could', 1), ('counterpart', 1), ('currently', 1), ('data', 1), ('datum', 4), ('delete', 1), ('deleterious', 1), ('deletion', 4), ('demonstrate', 1), ('derive', 1), ('describe', 2), ('detection', 1), ('determine', 2), ('develop', 2), ('disequilibrium', 1), ('distinction', 1), ('dna', 2), ('due', 2), ('each', 4), ('effect', 1), ('either', 1), ('emerge', 1), ('employ', 1), ('essentially', 1), ('estimate', 1), ('event', 2), ('example', 1), ('exchange', 1), ('exclusively', 1), ('expect', 2), ('expectation', 1), ('experiment', 1), ('extract', 1), ('fact', 2), ('finely', 1), ('first', 1), ('for', 6), ('form', 1), ('freely', 1), ('from', 5), ('gene', 3), ('general', 1), ('generalized', 1), ('generally', 1), ('genes', 1), ('genome', 5), ('genomic', 4), ('genotype', 3), ('genotyping', 1), ('germ', 2), ('hallmark', 1), ('haplotype', 3), ('have', 9), ('heterozygosity', 3), ('heterozygous', 2), ('high', 2), ('highly', 1), ('however', 1), ('identify', 3), ('ignore', 1), ('imbalance', 2), ('improve', 1), ('include', 1), ('increasingly', 1), ('indeed', 1), ('individual', 1), ('infer', 4), ('inference', 1), ('information', 1), ('initially', 1), ('interest', 1), ('introduction', 1), ('involve', 1), ('issue', 1), ('its', 1), ('just', 1), ('know', 1), ('knowledge', 2), ('last', 1), ('leave', 1), ('level', 3), ('line', 4), ('link', 1), ('linkage', 2), ('literature', 1), ('localization', 1), ('locally', 1), ('locus', 1), ('loh', 5), ('loss', 3), ('lung', 3), ('major', 1), ('make', 3), ('map', 1), ('marker', 1), ('match', 1), ('maximization', 1), ('may', 4), ('measure', 1), ('measurement', 1), ('mechanism', 2), ('merit', 1), ('method', 4), ('model', 2), ('monoallelic', 5), ('more', 1), ('mutant', 1), ('mutation', 2), ('natural', 1), ('normal', 2), ('not', 3), ('note', 1), ('novel', 1), ('nucleotide', 2), ('number', 12), ('occur', 2), ('oncogene', 2), ('oncogenic', 1), ('one', 3), ('only', 1), ('other', 2), ('our', 9), ('over', 1), ('package', 1), ('paper', 2), ('parent', 1), ('parental', 2), ('pcr', 1), ('phenomenon', 1), ('platform', 1), ('polymorphism', 2), ('portion', 1), ('potential', 1), ('precise', 1), ('presence', 1), ('present', 2), ('previously', 2), ('probe', 3), ('procedure', 2), ('produce', 1), ('propose', 1), ('pscn', 1), ('pscns', 1), ('quantitation', 2), ('question', 1), ('rather', 1), ('raw', 1), ('recent', 2), ('region', 5), ('remain', 1), ('research', 1), ('resolution', 1), ('responsible', 1), ('result', 3), ('reveal', 1), ('same', 1), ('sample', 7), ('scale', 1), ('select', 1), ('serve', 1), ('similarly', 1), ('single', 3), ('sister', 1), ('site', 3), ('snp', 4), ('software', 1), ('somatic', 1), ('specific', 7), ('statistically', 1), ('study', 5), ('subsequently', 1), ('such', 2), ('suggest', 2), ('suppressor', 1), ('target', 1), ('technology', 3), ('than', 2), ('that', 9), ('the', 38), ('their', 1), ('there', 1), ('these', 6), ('this', 6), ('those', 1), ('though', 1), ('throughput', 1), ('thus', 3), ('total', 2), ('tractable', 1), ('translocation', 1), ('true', 1), ('tumor', 4), ('two', 1), ('type', 2), ('typically', 2), ('unaltered', 1), ('unanswered', 1), ('under', 1), ('undergoe', 1), ('underlying', 1), ('unequal', 1), ('use', 4), ('validate', 1), ('variation', 1), ('variety', 2), ('various', 1), ('very', 1), ('via', 1), ('where', 2), ('wherein', 1), ('whether', 1), ('which', 2), ('while', 2), ('wide', 1), ('wild', 1), ('with', 3), ('would', 2), ('year', 2), ('yield', 1), ('zero', 1)], [('abstract', 1), ('addition', 2), ('allow', 1), ('also', 1), ('and', 11), ('apply', 1), ('approach', 3), ('base', 1), ('because', 1), ('between', 1), ('can', 2), ('candidate', 1), ('cell', 3), ('citation', 5), ('collection', 1), ('combine', 1), ('datum', 5), ('demonstrate', 1), ('describe', 1), ('develop', 2), ('example', 1), ('for', 7), ('from', 1), ('gene', 15), ('genome', 1), ('genomic', 1), ('have', 2), ('high', 1), ('however', 1), ('identify', 2), ('information', 3), ('interest', 1), ('introduction', 1), ('involve', 1), ('level', 1), ('major', 1), ('make', 1), ('map', 2), ('match', 1), ('may', 2), ('mechanism', 1), ('method', 5), ('model', 1), ('mutant', 1), ('natural', 1), ('not', 1), ('novel', 1), ('number', 2), ('one', 1), ('our', 1), ('presence', 1), ('present', 2), ('previously', 1), ('procedure', 1), ('region', 1), ('resolution', 4), ('reveal', 1), ('scale', 2), ('select', 1), ('single', 1), ('site', 1), ('subsequently', 1), ('that', 6), ('the', 29), ('these', 4), ('this', 8), ('two', 1), ('type', 1), ('use', 5), ('which', 1), ('with', 4), ('ability', 1), ('about', 1), ('accurately', 1), ('achieve', 1), ('adjust', 1), ('all', 1), ('although', 1), ('amount', 1), ('analogy', 1), ('anatomical', 4), ('anatomy', 1), ('annotate', 3), ('annotation', 8), ('applicable', 1), ('application', 1), ('associate', 2), ('atla', 1), ('atlas', 6), ('automate', 1), ('automatically', 1), ('barrelless', 1), ('begin', 1), ('biological', 1), ('boundary', 1), ('brain', 6), ('broad', 1), ('cellular', 2), ('change', 1), ('characterize', 1), ('collect', 1), ('common', 2), ('compare', 1), ('comparison', 3), ('completely', 1), ('complex', 2), ('computational', 1), ('context', 2), ('control', 1), ('coordinate', 1), ('cortex', 2), ('create', 1), ('creation', 1), ('critical', 1), ('curate', 1), ('curation', 1), ('custom', 1), ('database', 1), ('dataset', 3), ('day', 1), ('define', 2), ('deformable', 2), ('depict', 1), ('designation', 1), ('detect', 1), ('developmental', 1), ('dictionary', 1), ('digital', 3), ('dimensional', 1), ('directly', 1), ('discover', 1), ('disease', 1), ('dopamine', 1), ('down', 1), ('edinburgh', 2), ('effective', 1), ('efficient', 2), ('efficiently', 1), ('effort', 3), ('embryo', 1), ('establish', 1), ('exist', 1), ('exploit', 1), ('express', 1), ('expression', 15), ('extensive', 1), ('facilitate', 2), ('factor', 1), ('frame', 1), ('function', 1), ('functional', 1), ('future', 1), ('generate', 3), ('geometric', 1), ('group', 1), ('hand', 2), ('handle', 1), ('here', 4), ('hierarchical', 1), ('how', 1), ('hybridization', 1), ('illustration', 1), ('image', 4), ('important', 1), ('into', 2), ('ish', 2), ('laborious', 1), ('large', 3), ('layer', 1), ('limited', 2), ('location', 1), ('many', 1), ('massive', 1), ('mean', 3), ('meaningful', 1), ('mine', 2), ('modality', 1), ('modeling', 1), ('molecular', 2), ('mouse', 7), ('multi', 1), ('multitude', 1), ('nigra', 2), ('ontology', 1), ('organ', 1), ('parkinson', 1), ('particular', 1), ('pattern', 9), ('per', 1), ('place', 1), ('postnatal', 2), ('potentially', 1), ('process', 1), ('progress', 1), ('project', 3), ('protein', 2), ('prototype', 1), ('provide', 4), ('publish', 1), ('quantitative', 1), ('query', 3), ('range', 1), ('reference', 1), ('regionalization', 1), ('regulate', 2), ('relate', 1), ('relationship', 1), ('relative', 1), ('relatively', 1), ('represent', 1), ('representation', 2), ('require', 2), ('requirement', 1), ('retrieval', 1), ('review', 1), ('robotic', 2), ('rorb', 1), ('search', 2), ('section', 1), ('semi', 1), ('sequence', 1), ('situ', 1), ('small', 1), ('smooth', 1), ('somatosensory', 1), ('speciman', 2), ('specimen', 1), ('spectrum', 1), ('stage', 1), ('still', 1), ('strength', 2), ('structure', 3), ('substantia', 2), ('suitable', 1), ('systematically', 1), ('take', 1), ('technique', 2), ('term', 2), ('then', 2), ('therefore', 1), ('they', 1), ('three', 1), ('tissue', 2), ('tool', 1), ('transcript', 1), ('transcription', 1), ('transporter', 1), ('tree', 1), ('underlie', 1), ('update', 1), ('usefulness', 1), ('user', 2), ('utility', 2), ('vast', 1), ('visualization', 1), ('volumetric', 1), ('way', 1), ('when', 1), ('within', 1), ('without', 1), ('yet', 1)], [('abstract', 1), ('addition', 1), ('allele', 1), ('allow', 1), ('alteration', 2), ('analyze', 1), ('and', 18), ('available', 1), ('both', 2), ('can', 9), ('cancer', 1), ('cell', 4), ('citation', 20), ('constant', 2), ('copy', 1), ('datum', 1), ('demonstrate', 2), ('effect', 2), ('estimate', 1), ('example', 3), ('expect', 1), ('first', 1), ('for', 5), ('gene', 5), ('have', 5), ('highly', 3), ('however', 3), ('information', 1), ('introduction', 1), ('involve', 2), ('know', 4), ('loss', 2), ('may', 2), ('measure', 2), ('model', 1), ('more', 2), ('not', 2), ('occur', 1), ('one', 2), ('paper', 1), ('phenomenon', 2), ('recent', 1), ('research', 1), ('result', 3), ('scale', 2), ('single', 1), ('specific', 2), ('study', 1), ('such', 11), ('suggest', 3), ('suppressor', 3), ('target', 1), ('than', 1), ('that', 14), ('the', 36), ('their', 2), ('this', 6), ('thus', 3), ('total', 1), ('tumor', 4), ('two', 2), ('type', 3), ('under', 1), ('variety', 2), ('via', 2), ('where', 2), ('whether', 1), ('which', 4), ('while', 1), ('wild', 1), ('with', 4), ('about', 2), ('all', 4), ('although', 1), ('cellular', 14), ('change', 1), ('common', 1), ('coordinate', 2), ('disease', 1), ('establish', 1), ('exist', 1), ('expression', 10), ('factor', 1), ('function', 2), ('here', 3), ('how', 2), ('important', 1), ('large', 1), ('layer', 1), ('process', 1), ('protein', 13), ('range', 1), ('relatively', 1), ('require', 1), ('term', 3), ('they', 1), ('transcription', 4), ('vast', 1), ('within', 2), ('abrogate', 2), ('abundance', 1), ('account', 2), ('activate', 2), ('activation', 1), ('activator', 1), ('additionally', 1), ('administration', 1), ('advantageous', 1), ('affect', 4), ('alter', 6), ('amplitude', 1), ('apoptosis', 1), ('basal', 1), ('behavior', 1), ('bistability', 2), ('bring', 2), ('broadly', 1), ('carcinogenesis', 1), ('cascade', 4), ('case', 4), ('catalyzing', 2), ('circadian', 1), ('concentration', 4), ('condition', 1), ('confer', 1), ('constituent', 1), ('contribute', 2), ('correlate', 1), ('covalent', 1), ('crosstalk', 1), ('cycle', 3), ('cyclic', 1), ('cyclin', 1), ('decision', 2), ('degradation', 1), ('dependent', 1), ('dephosphorylation', 2), ('deregulated', 1), ('desensitization', 1), ('development', 1), ('diabetes', 1), ('difference', 1), ('different', 1), ('differentiation', 2), ('discriminate', 1), ('downstream', 1), ('dramatically', 1), ('during', 2), ('early', 3), ('elicit', 2), ('encode', 1), ('enzymatic', 1), ('enzyme', 3), ('equally', 1), ('eukaryotic', 1), ('even', 3), ('exhibit', 2), ('experimental', 2), ('experimentally', 2), ('extracellular', 3), ('fashion', 3), ('fast', 5), ('fate', 2), ('favor', 1), ('feedback', 1), ('figure', 2), ('finally', 3), ('fold', 1), ('follow', 1), ('fundamental', 1), ('furthermore', 3), ('glance', 1), ('guanosine', 1), ('half', 1), ('halve', 2), ('haploinsufficiency', 2), ('haploinsufficient', 1), ('help', 1), ('heterogeneity', 2), ('heterologous', 2), ('hit', 1), ('homozygotic', 1), ('hormone', 6), ('hour', 1), ('hypothesis', 1), ('immediate', 3), ('immune', 1), ('impact', 1), ('increase', 2), ('indicate', 1), ('induce', 8), ('induction', 3), ('influence', 1), ('inhibitor', 1), ('insensitive', 1), ('instead', 1), ('interested', 1), ('intermediate', 4), ('intracellular', 2), ('investigate', 1), ('kinase', 5), ('kinetic', 1), ('knudsons', 1), ('least', 1), ('less', 2), ('life', 1), ('like', 2), ('likewise', 1), ('linear', 1), ('long', 2), ('mainly', 1), ('majority', 2), ('minor', 2), ('minute', 1), ('mitogenic', 1), ('mkp', 1), ('mode', 1), ('moderate', 1), ('modification', 2), ('modularity', 2), ('monophosphate', 1), ('most', 3), ('motif', 1), ('mrna', 2), ('mrnas', 2), ('multiple', 2), ('negative', 1), ('network', 1), ('noise', 2), ('none', 3), ('nonlinearitie', 1), ('nonlinearity', 1), ('nucleus', 1), ('observe', 3), ('often', 1), ('operate', 2), ('order', 1), ('oscillation', 2), ('overlap', 1), ('owe', 2), ('own', 2), ('parameter', 1), ('particularly', 1), ('pathological', 1), ('pathway', 1), ('peptide', 1), ('phosphatase', 2), ('phosphoprotein', 3), ('phosphorylate', 1), ('phosphorylation', 6), ('physiological', 2), ('physiologically', 1), ('pool', 1), ('positive', 1), ('possible', 1), ('posttranslational', 1), ('potentiation', 1), ('pre', 1), ('previous', 1), ('probably', 1), ('processing', 1), ('progression', 1), ('pronounce', 2), ('pronounced', 1), ('proteolytic', 1), ('rate', 1), ('ratio', 1), ('receptor', 3), ('reduction', 2), ('refer', 3), ('regulation', 17), ('repress', 1), ('respect', 1), ('response', 4), ('rhythm', 1), ('saturate', 1), ('sensitization', 2), ('sequester', 1), ('sequestration', 1), ('set', 1), ('several', 1), ('show', 6), ('signal', 20), ('signaling', 1), ('significant', 1), ('simple', 1), ('simplified', 1), ('since', 1), ('slow', 4), ('some', 1), ('specificity', 3), ('state', 1), ('steady', 1), ('stimulus', 3), ('strong', 2), ('strongly', 1), ('subject', 4), ('substrate', 3), ('sufficient', 1), ('support', 1), ('switch', 2), ('synthesis', 1), ('system', 1), ('theoretical', 1), ('third', 1), ('time', 2), ('towards', 1), ('transcriptional', 4), ('transduce', 1), ('transduction', 7), ('transfer', 1), ('transmission', 6), ('turn', 3), ('tyrosine', 2), ('ultrasensitive', 2), ('ultrasensitization', 13), ('unclear', 1), ('upon', 1), ('upstream', 2), ('usually', 1), ('view', 1), ('well', 1), ('will', 3)]]\n"]}]},{"cell_type":"markdown","source":["For semantic search"],"metadata":{"id":"m4sRQJAJ_Rhn"}},{"cell_type":"code","source":["# Load and preprocess documents\n","filenames = []\n","texts_semantic = []\n","for filename in os.listdir(document_dir):\n","    if filename.endswith(\".txt\"):\n","        filepath = os.path.join(document_dir, filename)\n","        with open(filepath, 'r', encoding='utf-8') as file:\n","            text = file.read()\n","            processed_text = preprocess(text, use_for='semantic')\n","            texts_semantic.append(processed_text)\n","            filenames.append(filename)"],"metadata":{"id":"GjbcURYLCly3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Comparison"],"metadata":{"id":"vTk3MGYZ_Von"}},{"cell_type":"code","source":["query = \"How to preprocess text in Python? Exploring text preprocessing techniques.\"\n","\n","print(preprocess(query, use_for='keyword'))\n","print(preprocess(query, use_for='semantic'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8BwjEpQcklLa","executionInfo":{"status":"ok","timestamp":1710520893736,"user_tz":420,"elapsed":386,"user":{"displayName":"Shawon Sarkar","userId":"05628563176525096143"}},"outputId":"3940e4bd-777a-47e1-de39-c6fb8799fa08"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['how', 'preprocess', 'text', 'python', 'explore', 'text', 'preprocesse', 'technique']\n","How to preprocess text in Python  Exploring text preprocessing techniques\n"]}]},{"cell_type":"markdown","source":["Embedding\n","\n","In practice we need to run the embedding model twice:\n","\n","Indexing Stage: This is an offline process where the document collection is transformed into embeddings in a batch operation. While this stage demands high computational throughput, it is not latency-sensitive. The goal here is to precompute and store the embeddings for all documents in the database, facilitating efficient retrieval during the search.\n","\n","Query Embedding: At the time of each search request, the query itself is converted into an embedding. This operation is online and requires prompt execution to ensure a swift response to the search inquiry. Despite the need for speed, this process benefits from the models' ability to understand and match the query's semantic context with the precomputed document embeddings."],"metadata":{"id":"ySjy5Q3Rls3U"}},{"cell_type":"markdown","source":["TF-IDF Embeddings for keyword-based search"],"metadata":{"id":"foBeM1BRFuh7"}},{"cell_type":"code","source":["# Initialize and train the TF-IDF model\n","tfidf = models.TfidfModel(corpus)  # fit TF-IDF model\n","\n","# Apply transformation to the entire corpus\n","tfidf_corpus = [tfidf[doc] for doc in corpus]"],"metadata":{"id":"KuY4WgM9EwOh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Semantic Embeddings\n","\n","Most popular transformer-based models.\n","\n","The architecture of the Transformer model is built around two main components:\n","\n","Encoder: This component processes textual input, which has been converted into numerical format, to generate embeddings that encapsulate the semantic essence of the input text.\n","\n","Decoder: This part reverses the encoder's operation. Starting from the embeddings, it generates predictions for the subsequent text token.\n","\n","Positioned at the heart of this structure, between the encoder and decoder, lies the embedding representation of the input. It's crucial to distinguish between the input vectors and the embedding vectors, despite both being numerical arrays:\n","\n","Input Vectors: These are essentially sequences of term identifiers, each selected from a predefined vocabulary for instance, BERT operates with a vocabulary size of about 32,000 terms, and are padded to maintain a uniform length across inputs.\n","\n","Embedding Vectors: Represent the model's internal interpretation of the input. They are the \"lens\" through which the neural network perceives your data. It's reasonable to anticipate that documents bearing semantic similarities will yield closely related internal representations.\n","\n","Models like BERT are tailored to utilize solely the encoder segment of the Transformer architecture. They excel in tasks such as text classification, summarization, and entity recognition, owing to their ability to deeply understand and represent the semantics of text.\n","\n","Conversely, models from the GPT family employ only the decoder component. Their strengths lie in generating coherent and contextually relevant text based on the embeddings, showcasing their proficiency in tasks that involve text creation and completion."],"metadata":{"id":"zx-sp_SUlx6h"}},{"cell_type":"markdown","source":["Semantic embedding using a sentence transformer model"],"metadata":{"id":"NOHm72JQrrrI"}},{"cell_type":"code","source":["# Load a pre-trained model # We will use a small model due to memory constraint\n","model = SentenceTransformer('all-MiniLM-L6-v2')"],"metadata":{"id":"4t5_2TPOF2_C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_sentence_embeddings(documents):\n","    \"\"\"\n","    Generates embeddings for a list of documents using a Sentence Transformer model.\n","\n","    Parameters:\n","    - documents: A list of strings (documents or sentences) to be embedded.\n","\n","    Returns:\n","    - An array of embeddings.\n","    \"\"\"\n","    # Generate embeddings\n","    embeddings = model.encode(documents, show_progress_bar=True)\n","    return embeddings"],"metadata":{"id":"QYZZkbmlF7Cs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Search"],"metadata":{"id":"XB5sGSj7F8a7"}},{"cell_type":"markdown","source":["Basic Information Retrieval with TF-IDF for keyword-based search"],"metadata":{"id":"WJWw34gXx8aZ"}},{"cell_type":"code","source":["def tfidf_search(query, dictionary, tfidf_model, dense_tfidf):\n","    \"\"\"\n","    Search the corpus using a TF-IDF representation and cosine similarity.\n","\n","    Parameters:\n","    - query: The search query as a string.\n","    - dictionary: The Gensim dictionary mapping of ids to terms.\n","    - tfidf_model: The trained Gensim TF-IDF model.\n","    - dense_tfidf: The dense TF-IDF representation of the entire corpus.\n","\n","    Returns:\n","    - A list of tuples (document_index, similarity_score) sorted by similarity score in descending order.\n","    \"\"\"\n","    # Preprocess and vectorize the query in the same way as the corpus\n","    query_bow = dictionary.doc2bow(query.lower().split())\n","    query_tfidf = tfidf_model[query_bow]\n","    query_dense = matutils.sparse2full(query_tfidf, len(dictionary))\n","\n","    # Calculate cosine similarity between the query and all documents\n","    similarities = []\n","    for doc in dense_tfidf:\n","        sim = 1 - spatial.distance.cosine(query_dense, doc)\n","        similarities.append(sim)\n","\n","    # Sort documents by their similarity to the query\n","    sorted_similarities = sorted(enumerate(similarities), key=lambda x: x[1], reverse=True)\n","\n","    return sorted_similarities"],"metadata":{"id":"_VynuIiSBUb6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Extending to Semantic Search\n","Now, let's implement a semantic search function using sentence transformers for more meaningful searches."],"metadata":{"id":"xbbzayv1yDwg"}},{"cell_type":"markdown","source":["Semantic search with all-MiniLM-L6-v2\n","\n","The smaller the model, the lower the search latency and the faster the indexing speed. Huge SGPT and GTR models can only run on expensive GPUs.\n","\n","The larger the number of parameters in the model, the better retrieval quality. all-MiniLM-L6-v2 is a good model, but it is too small to catch all the semantic differences in search with its 10M parameters. (Rank #72 for retrieval for BEIR/MTEB benchmark)\n","\n","Ranking: https://huggingface.co/spaces/mteb/leaderboard"],"metadata":{"id":"HXP6WjWZpZ--"}},{"cell_type":"code","source":["def semantic_search(query, documents, top_k=5):\n","    \"\"\"\n","    Performs semantic search to find the most similar documents to the query.\n","\n","    Parameters:\n","    - query: A string representing the search query.\n","    - documents: A list of strings representing the documents.\n","    - top_k: The number of top similar documents to return.\n","\n","    Returns:\n","    - A list of tuples (document index, similarity score) for the top_k most similar documents.\n","    \"\"\"\n","    query_embedding = model.encode([query])\n","    document_embeddings = get_sentence_embeddings(documents)\n","\n","    # Calculate cosine similarities\n","    similarities = cosine_similarity(query_embedding, document_embeddings)[0]\n","\n","    # Get top_k most similar documents\n","    top_k_indices = np.argsort(similarities)[::-1][:top_k]\n","\n","    return [(index, similarities[index]) for index in top_k_indices]"],"metadata":{"id":"_VEJVYokyDXN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Run"],"metadata":{"id":"uktNWZKJn6Fk"}},{"cell_type":"code","source":["# Example query\n","query = \"what is a phylogenetic context\"\n","\n","# Perform semantic search\n","results = semantic_search(query, texts_semantic, top_k=5)\n","\n","# Display the results\n","for idx, score in results:\n","    print(f\"Document index: {idx}, Similarity score: {score:.4f}, Filename: {filename}\")"],"metadata":{"id":"wGszqsU2n79m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example usage of the tfidf_search function\n","query = \"what is a phylogenetic context\"\n","search_results = tfidf_search(query, dictionary, tfidf, dense_tfidf)\n","\n","# Display top 5 results with correct filename retrieval\n","for doc_index, sim_score in search_results[:5]:\n","    filename = document_filenames[doc_index]\n","    print(f\"Document index: {doc_index}, Similarity score: {sim_score:.4f}, Filename: {filename}\")"],"metadata":{"id":"h_Hysefm9_I0"},"execution_count":null,"outputs":[]}]}